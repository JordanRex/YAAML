{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test nb for fasttext supervised binary classification ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', '1_12_52_25_10_2018.pickle', '1_t_h2o.csv', '1_v_h2o.csv', '2_12_53_25_10_2018.pickle', '2_t_h2o.csv', '2_v_h2o.csv', '3_12_55_25_10_2018.pickle', '3_t_h2o.csv', '3_v_h2o.csv', 'april_17.csv', 'aug_16.csv', 'aug_17.csv', 'automl_new.ipynb', 'dec_16.csv', 'fasttext example.ipynb', 'feb_17.csv', 'I3_LighGBM_plus_Lime - Reduced Factors-v4.ipynb', 'jan_17.csv', 'july_16.csv', 'july_17.csv', 'JUNE18_TURNOVER.xlsx', 'june_16.csv', 'june_17.csv', 'MAIN_new.ipynb', 'mar_17.csv', 'may_17.csv', 'NEW.rar', 'nov_16.csv', 'nov_17.csv', 'oct_16.csv', 'oct_17.csv', 'plot_document_classification_20newsgroups.ipynb', 'sep_16.csv', 'sep_17.csv', 'test.txt', 'test_dfs.csv', 'TRAIN.csv', 'train.txt', 'Turnover Report NAZ 2017 Year End.csv', 'turnover-2016-final.csv', 'VALID.csv']\n"
     ]
    }
   ],
   "source": [
    "# clear the workspace\n",
    "%reset -f\n",
    "\n",
    "# print list of files in directory\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "# the base packages\n",
    "import collections # for the Counter function\n",
    "import pandas as pd, numpy as np, re\n",
    "import sklearn.metrics\n",
    "\n",
    "# utilities options\n",
    "randomseed = 1 # the value for the random state used at various points in the pipeline\n",
    "pd.options.display.max_rows = 1000 # specify if you want the full output in cells rather the truncated list\n",
    "pd.options.display.max_columns = 200\n",
    "# to display multiple outputs in a cell without usin print/display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find and append multiple dataframes of the type specified in string\n",
    "def append_datasets(cols_to_remove, string = ['TRAIN', 'VALID']):\n",
    "    # pass either train or valid as str argument\n",
    "    temp_files = [name for name in os.listdir() if name.startswith(string)]\n",
    "    temp_dict = {}\n",
    "    for i in temp_files:\n",
    "        df_name = re.sub(string=i, pattern='.csv', repl='')\n",
    "        print(df_name)\n",
    "        temp_dict[df_name] = pd.read_csv(i, na_values=['No Data', ' ', 'UNKNOWN', ''])\n",
    "        temp_dict[df_name].columns = map(str.lower, temp_dict[df_name].columns)\n",
    "        temp_dict[df_name].drop(cols_to_remove, axis = 1, inplace = True)\n",
    "        chars_to_remove = [' ', '.', '(', ')', '__', '-']\n",
    "        for i in chars_to_remove:\n",
    "            temp_dict[df_name].columns = temp_dict[df_name].columns.str.strip().str.lower().str.replace(i, '_')\n",
    "    temp_list = [v for k,v in temp_dict.items()]\n",
    "    temp = pd.concat(temp_list, axis=0, sort=True, ignore_index=True)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "VALID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# input/ouput files\n",
    "\n",
    "cols_to_remove = ['global id']\n",
    "train = append_datasets(string='TRAIN', cols_to_remove=cols_to_remove)\n",
    "test = append_datasets(string='VALID', cols_to_remove=cols_to_remove)\n",
    "\n",
    "text_cols = ['short_text_of_organizational_unit', 'position_text', 'abinbev_entity4', 'physical_work_location_description',\n",
    "            'physical_work_location_description', 'physical_work_location_city', 'physical_work_location_city', \n",
    "            'manager_position_desc', 'costcenter_description', 'macro_entity4', 'abinbev_entity3',\n",
    "            'local_entity_description', 'pers_subarea_text', 'group', 'abinbev_entity2', 'global_job', 'job_family',\n",
    "            'functional_area']\n",
    "train_text = train[text_cols]\n",
    "test_text = test[text_cols]\n",
    "train_text['string_all'] = train_text[text_cols].apply(lambda x: ' '.join(x.dropna()), axis=1)\n",
    "test_text['string_all'] = test_text[text_cols].apply(lambda x: ' '.join(x.dropna()), axis=1)\n",
    "train_text = train_text[['string_all']]\n",
    "test_text = test_text[['string_all']]\n",
    "y_train = train[['label']]\n",
    "y_test = test[['label']]\n",
    "\n",
    "train_final = pd.concat([y_train.reset_index(drop=True), train_text.reset_index(drop=True)], axis=1)\n",
    "test_final = pd.concat([y_test.reset_index(drop=True), test_text.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final['string'] = '__label__' + train_final['label'].astype('str') + ' ' + train_final['string_all']\n",
    "test_final['string'] = '__label__' + test_final['label'].astype('str') + ' ' + test_final['string_all']\n",
    "\n",
    "train_final.drop(['label', 'string_all'], inplace=True, axis=1)\n",
    "test_final.drop(['label', 'string_all'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.to_csv('train.txt', encoding='utf-8', index=False, header=False, sep='\\t')\n",
    "test_final.to_csv('test.txt', encoding='utf-8', index=False, header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import train_supervised\n",
    "\n",
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_supervised(input = 'train.txt', epoch=10000, lr=0.01, wordNgrams=6, verbose=10, minCount=1, loss='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t5734\n",
      "P@1\t0.928\n",
      "R@1\t0.928\n"
     ]
    }
   ],
   "source": [
    "print_results(*model.test('test.txt', k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = test_final.shape[0]\n",
    "\n",
    "predict_list = [None] * test_len\n",
    "iter = 0\n",
    "for i in range(test_len):\n",
    "    x=model.predict(test_text.iloc[iter][0], k=2)\n",
    "    y=pd.DataFrame(list(x))\n",
    "    y.columns=y.iloc[0]\n",
    "    y=y.reindex(y.index.drop(0))\n",
    "    predict_list[iter] = float(y['__label__1'])\n",
    "    iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6748679919571519"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(y_score=predict_list, y_true=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
